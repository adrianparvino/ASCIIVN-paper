#+OPTIONS: toc:nil

#+LATEX_HEADER: \newcommand\nl{\\}
#+TITLE: Visual novel engine for textual displays

# #+TITLE: Are there bactrians or dromedaries in University of San Carlos:
# #+TITLE: Verification and meta-analysis of the supposed double hump in Computer
# #+TITLE: Science
#+AUTHOR: Adrian Parvin D. Ouano
#+EMAIL: adrianparvino@gmail.com

#+LATEX_CLASS_OPTIONS: [12pt]
#+LATEX_HEADER: \newif\ifexport
#+LATEX_HEADER: \usepackage[top=2.54cm,bottom=2.54cm,right=2.54cm,left=3.81cm]{geometry}
# #+LATEX_HEADER: \usepackage{microtype}
#+LATEX_HEADER: \usepackage{indentfirst}
#+LATEX_HEADER: \usepackage{ragged2e}

#+LATEX_HEADER: \usepackage{siunitx}
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage[final]{pdfpages}

#+LATEX_HEADER: \usepackage{xstring}
#+LATEX_HEADER: \usepackage[english]{babel}
#+LATEX_HEADER: \usepackage{datetime}
#+LATEX_HEADER: \usepackage{csquotes}
#+LATEX_HEADER: \usepackage[style=apa, backend=biber, natbib=true] {biblatex}
#+LATEX_HEADER: \DeclareLanguageMapping{english}{english-apa}
#+LATEX_HEADER: \makeatletter
#+LATEX_HEADER: \def\blx@maxline{77}
#+LATEX_HEADER: \makeatother
#+LATEX_HEADER: \addbibresource{Research.bib}
#+LATEX_HEADER: \usepackage{fancyhdr}
#+LATEX_HEADER: \usepackage{glossaries}
#+LATEX_HEADER: \usepackage{titlesec}
#+LATEX_HEADER: \usepackage{tocloft}
#+LATEX_HEADER: \usepackage{verbatim}
#+LATEX_HEADER: \usepackage{setspace}
#+LATEX_HEADER: \usepackage{pgfgantt}
#+LATEX_HEADER: \usepackage{float}
#+LATEX_HEADER: \usepackage{ulem}
#+LATEX_HEADER: \usepackage{mathtools}
#+LATEX_HEADER: \usepackage{enumitem}
#+LATEX_HEADER: \renewcommand{\cite}{\textcite}

#+LATEX_HEADER: \DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

#+LATEX_HEADER: \newcommand{\listappendicesname}{Appendices}
#+LATEX_HEADER: \newlistof{appendices}{apc}{\listappendicesname}
#+LATEX_HEADER: \newcommand{\appendices}[1]{\addcontentsline{apc}{appendices}{#1}}
#+LATEX_HEADER: \newcommand{\newappendix}[1]{\subsection*{#1}\appendices{#1}}

#+LATEX_HEADER: \exporttrue

#+LATEX_HEADER: \ifexport
#+LATEX_HEADER:   \makeatletter
#+LATEX_HEADER:   \patchcmd{\l@section}
#+LATEX_HEADER:      {\cftsecfont #1} %   search pattern
#+LATEX_HEADER:      {\cftsecfont {#1}} % replace by
#+LATEX_HEADER:      {} %                  success
#+LATEX_HEADER:      {} %                  failure
#+LATEX_HEADER:   \makeatother
#+LATEX_HEADER: \fi

# #+LATEX_HEADER: \ifexport \renewcommand{\thesection}{\Roman{section}} \fi
#+LATEX_HEADER: \ifexport \usepackage{fontspec} \fi
#+LATEX_HEADER: \ifexport \setmainfont{Times New Roman} \fi
#+LATEX_HEADER: \ifexport \renewcommand{\baselinestretch}{2} \fi
#+LATEX_HEADER: \ifexport \titleformat{\section}[display]{\setstretch{1}\centering}{\bf CHAPTER \thesection}{5pt}{\bf} \fi
# #+LATEX_HEADER: \ifexport \titleformat{\section}[display]{\setstretch{1.6}\centering}{CHAPTER \thesection}{5pt}{\bf\MakeUppercase} \fi
#+LATEX_HEADER: \ifexport \titleformat{\subsection}{}{}{0in}{\uline} \fi
#+LATEX_HEADER: \ifexport \titleformat{\subsubsection}[runin]{}{}{0.5in}{\itshape}[.] \fi
#+LATEX_HEADER: \ifexport \setlength{\parindent}{0.5in} \fi
#+LATEX_HEADER: \ifexport \renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}} \fi
#+LATEX_HEADER: \ifexport \renewcommand{\cfttableader}{\hfill} \fi
#+LATEX_HEADER: \ifexport \renewcommand{\cftfigleader}{\hfill} \fi
# #+LATEX_HEADER: \ifexport \renewcommand{\cftdot}{} \fi
#+LATEX_HEADER: \ifexport \input{TitlePage.tex} \fi
#+LATEX_HEADER: \ifexport \renewcommand\cftsecpagefont{\textnormal}\fi
#+LATEX_HEADER: \ifexport \cftsetindents{section}{0em}{2em} \fi
#+LATEX_HEADER: \ifexport \cftsetindents{subsection}{0.5in}{2em} \fi
#+LATEX_HEADER: \ifexport \cftsetindents{subsubsection}{1in}{2em} \fi
#+LATEX_HEADER: \ifexport \setlength\cftbeforesubsecskip{-12pt} \fi
#+LATEX_HEADER: \ifexport
#+LATEX_HEADER:   \makeatletter
#+LATEX_HEADER:   \renewcommand\tagform@[1]{\maketag@@@{\ignorespaces#1\unskip\@@italiccorr}}
#+LATEX_HEADER:   \makeatother
#+LATEX_HEADER:   \renewcommand{\theequation}{Equation \arabic{equation}}
#+LATEX_HEADER: \fi
#+LATEX_HEADER: \ifexport
#+LATEX_HEADER:   \makeatletter
#+LATEX_HEADER:   \newlength\mylength
#+LATEX_HEADER:   \setlength{\cftsecnumwidth}{1em}
#+LATEX_HEADER:   \settowidth\mylength{\cftsecpresnum\cftsecaftersnum\quad}
#+LATEX_HEADER:   \addtolength\cftsecnumwidth{\mylength}
#+LATEX_HEADER:   \renewcommand\cftsecpresnum{CHAPTER~}
#+LATEX_HEADER:   \renewcommand\cftsecaftersnum{}
# #+LATEX_HEADER:   \renewcommand\cftsecfont{\textbf\uppercase}
#+LATEX_HEADER:   \renewcommand\cftsecfont{\textbf}
#+LATEX_HEADER:   \settowidth\mylength{\cftsecpresnum\cftsecaftersnum\quad}
#+LATEX_HEADER:   \addtolength\cftsecnumwidth{\mylength}
#+LATEX_HEADER:   \renewcommand{\cftsubsecpresnum}{\begin{lrbox}{\@tempboxa}}
#+LATEX_HEADER:   \renewcommand{\cftsubsecaftersnum}{\end{lrbox}}
#+LATEX_HEADER:   \setlength{\cftsubsecnumwidth}{0pt}
#+LATEX_HEADER:   \renewcommand{\cftsubsubsecpresnum}{\begin{lrbox}{\@tempboxa}}
#+LATEX_HEADER:   \renewcommand{\cftsubsubsecaftersnum}{\end{lrbox}}
#+LATEX_HEADER:   \setlength{\cftsubsubsecnumwidth}{0pt}
#+LATEX_HEADER:   \makeatother
#+LATEX_HEADER: \fi

#+LATEX_HEADER: \addto\captionsenglish{\renewcommand\contentsname{\clearpage\bf \normalsize \begin{center} TABLE OF CONTENTS \end{center} Title \hfill PAGE}}
#+LATEX_HEADER: \addto\captionsenglish{\renewcommand\listtablename{\clearpage\bf \normalsize \begin{center} LIST OF TABLES \end{center} TABLE \hfill TITLE \hfill PAGE}}
#+LATEX_HEADER: \addto\captionsenglish{\renewcommand\listfigurename{\clearpage\bf \normalsize \begin{center} LIST OF FIGURES \end{center} FIGURE \hfill TITLE \hfill PAGE}}
#+LATEX_HEADER: \addto\captionsenglish{\renewcommand\listappendicesname{\clearpage\bf \normalsize \begin{center} LIST OF APPENDICES \end{center} FIGURE \hfill TITLE \hfill PAGE}}

#+LATEX_HEADER: \fancypagestyle{plain}{
#+LATEX_HEADER:   \fancyhf{}
#+LATEX_HEADER:   \renewcommand{\headrulewidth}{0pt}
#+LATEX_HEADER: }

#+LATEX_HEADER: \fancyhf{}
#+LATEX_HEADER: \renewcommand{\headrulewidth}{0pt}
#+LATEX_HEADER: \fancyfoot[R]{\thepage}

#+LATEX_HEADER: \definecolor{dkgreen}{rgb}{0,0.6,0}
#+LATEX_HEADER: \definecolor{mauve}{rgb}{0.878,0.69,1.0}
#+LATEX_HEADER: \newcommand{\sectionbreak}{\clearpage \thispagestyle{empty}}
#+LATEX_HEADER: \lstset{frame=tb,
#+LATEX_HEADER:   language=C,
#+LATEX_HEADER:   aboveskip=3mm,
#+LATEX_HEADER:   belowskip=3mm,
#+LATEX_HEADER:   showstringspaces=false,
#+LATEX_HEADER:   columns=flexible,
#+LATEX_HEADER:   basicstyle={\small\ttfamily\setstretch{1}},
#+LATEX_HEADER:   numbers=none,
#+LATEX_HEADER:   numberstyle=\tiny\color{gray},
#+LATEX_HEADER:   keywordstyle=\color{blue},
#+LATEX_HEADER:   commentstyle=\color{dkgreen},
#+LATEX_HEADER:   stringstyle=\color{mauve},
#+LATEX_HEADER:   breaklines=true,
#+LATEX_HEADER:   breakatwhitespace=true,
#+LATEX_HEADER:   tabsize=3
#+LATEX_HEADER: }


#+LATEX_HEADER: \newcommand{\iffielddef}[3]{\iffieldundef{#1}{#3}{#2}}
#+LATEX_HEADER: \defbibcheck{website}{
#+LATEX_HEADER:   \iffielddef{doi}{\skipentry}{
#+LATEX_HEADER:     \iffieldundef{url}{\skipentry}{}
#+LATEX_HEADER:   }
#+LATEX_HEADER: }
#+LATEX_HEADER: \defbibcheck{journal}{
#+LATEX_HEADER:   \iffielddef{url}{\iffieldundef{doi}{}{\skipentry}}{}
#+LATEX_HEADER:   \iffielddef{journaltitle}{}{
#+LATEX_HEADER:     \iffieldundef{booktitle}{\skipentry}{}
#+LATEX_HEADER:   }
#+LATEX_HEADER: }
#+LATEX_HEADER: \defbibcheck{article}{
#+LATEX_HEADER:   \iffielddef{url}{\iffieldundef{doi}{}{\skipentry}}{}
#+LATEX_HEADER:   \iffielddef{journaltitle}{\skipentry}{}
#+LATEX_HEADER:   \iffielddef{booktitle}{\skipentry}{}
#+LATEX_HEADER: }


# #+LATEX_HEADER: \defbibcheck{skipwithurl}{\iffieldundef{url}{}{\skipentry}}
# #+LATEX_HEADER: \defbibcheck{includewithurl}{\iffieldundef{url}{\skipentry}{}}
# #+LATEX_HEADER: \defbibcheck{skipwithjournal}{\iffieldundef{booktitle}{}{\skipentry}}
# #+LATEX_HEADER: \defbibcheck{includewithjournal}{\iffieldundef{booktitle}{\skipentry}{}}

#+LATEX: \clearpage
# #+LATEX: \thispagestyle{empty}
# #+LATEX: \twocolumn
# #+LATEX: \ifexport\onecolumn\fi

#+LATEX: \renewcommand{\thepage}{\roman{page}}
* APPROVAL SHEET
  :PROPERTIES:
  :UNNUMBERED: t
  :END:
#+LATEX: {
# #+LATEX: \thispagestyle{empty}
#+LATEX: \setstretch{1}
#+LATEX: \addcontentsline{toc}{section}{APPROVAL SHEET}
#+LATEX: \makeatletter
This research entitled
#+LATEX: ``\textit{\textbf{\@title}}''
submitted by
*OSCAR III CABARRON*,
*KYLE PATRICK GO*,
*ADRIAN PARVIN OUANO*,
*ADRIAN SARMIENTO*, and
*GADDIEL ANTHONY TEVES*
in partial fulfillment for the
subject RESEARCH CAPSTONE PROJECT.
Have been review by the panel of examinees.
And is recommended for acceptance and approval.
#+LATEX: \makeatother

#+LATEX: \vfill

\begin{center}
\underline{EVANGELIN D. PIANDONG}\nl
Adviser
\end{center}

#+LATEX: \vfill

Accepted and approved in partial fulfillment of the requirements for the subject
RESEARCH CAPSTONE PROJECT.

#+LATEX: \vfill

\begin{center}
\underline{MELANIE G. BAREJA, MSc.}\nl
Coordinator, STEM Strand
\end{center}

#+LATEX: \vfill

\begin{center}
\underline{RIZA, ALFAFARA, MAED}\nl
Principal, Senior High School
\end{center}
#+LATEX: \vfill
#+LATEX: \vfill

#+LATEX: }

* ABSTRACT
  :PROPERTIES:
  :UNNUMBERED: t
  :END:
#+LATEX: \addcontentsline{toc}{section}{ABSTRACT}
#+LATEX: {
# #+LATEX: \thispagestyle{empty}
#+LATEX: \setstretch{1}
In the study, we designed a program that can convert images to ASCII art.
A survey was conducted comparing the original image and the rendered image with clarity and accuracy as the criteria.
A total of 60 students from University of San Carlos were surveyed in the study.
The results were that the rendered image was clear and accurate for the students to compare it to the original image.
Furthermore, 9144 images from cite:fei2007learning were rendered and none of the images crashed the program.
Overall, the program produced satisfactory results and the code was considered correct.

#+LATEX: }

* ACKNOWLEDGEMENT
  :PROPERTIES:
  :UNNUMBERED: t
  :END:
#+LATEX: \addcontentsline{toc}{section}{ACKNOWLEDGEMENT}
# #+LATEX: \thispagestyle{empty}
We would like to thank the Almighty God for giving us guidance and the opportunity to create and present this study.

We also sincerely thank Ms. Evangelin Diaz Piandong and the rest of the USC organization
for the guidance and encouragement in carrying out this project work.

We are also thankful for our parents for their undying love and support during the creation of this paper.

We wish to extend our sincere gratitude to the students that answered the surveys
that gave us enough information for us to improve this program.

#+LATEX: \clearpage{}
#+LATEX: \pagestyle{empty}
#+TOC: headlines 2
#+TOC: tables
# #+LATEX: \listoffigures
#+LATEX: \listofappendices

* INTRODUCTION
#+LATEX: \pagestyle{fancy}
#+LATEX: \setcounter{page}{1}
#+LATEX: \renewcommand{\thepage}{\arabic{page}}
** Rationale
This research was an application of our Computer Programming course.
In the research, the American Standard Code for Information Interchange(ASCII) art was explored.
This form of art was once prevalent however due to the increasing graphical capabilities of computers, it quickly subsided into a niche.
The aim was to develop an engine which would convert visual images to ASCII art, and apply it to various forms of media,
such as visual novels, text-based games, or animations.
Theoretically, the produced code was also optimized for SIMD-capable processors,
however the main target was the x86-64 class of processors which supports AVX2, as
the data were 32-byte aligned and were grouped as 8 elements of 4-byte data structure, specifically \lstinline{int} and \lstinline{float}.

** Statement of the Problem
This study aimed to integrate Visual images to two forms of ASCII art.

Specifically, this study aimed to:
#+ATTR_LATEX: :environment enumerate
#+ATTR_LATEX: :options [leftmargin=1in]
1. program a visual novel engine displaying ASCII art
2. test if the engine was fully functional
3. compare the visual image with the converted ASCII art

** Significance of the Study
This study contributes to the field of visual recognition.
The success of this study provided clues on the information relevant to recognizability of images.
It also experiments with the mixture of two rendering methods and compositing it into one image in order to enhance the quality of the image.
Due to the inherent characteristics of the program, it also has the advantage of being able to be used in text-only displays
such as the HD44780 which was a controller for character-based liquid crystal displays, and older phones and pagers; and also be used in bad signal conditions.
ASCII art has long been used to visually represent complex structures on chat systems such as Internet Relay Chat, and
also in the days of modem as not only was the internet connection limited,
it was too slow to reasonably load images; without ASCII art,
complex structures would be impossible to transfer in a reasonable amount of time for real-time communication.

Facebook has created a neural network that detects the components of a scene and provides an automatic description, however,
it was unable to understand lower level constructs such as structures and context.
To provide an example, the neural network may output ``1 smiling person,''
however that gives no information on how the person smiled,
and even worse, it doesn't /show/ how the person looks like.
This research was able to alleviate that problem by re-creating the image.
If the image was accurate enough, it can also serve as a preview of the image.

** Scope and Limitation
The study was conducted within a span of three months,
with a month dedicated to experimentation and a week for survey to receive feedback
regarding our product and was aimed at sample who were experienced in either art or gaming.

The study was limited to the usage of the C programming language,
a mix of line and field art as other forms of computer art were not studied and compared.
In addition, this study was focused on the creation of our product and was not meant to be compared to other researches.
We however compared the results of the program to the original image,
in order to measure the clarity and the accuracy of the generated ASCII art.
Colors were also not explored in this research meaning that although the art scanned in the program was colored,
the converted ASCII art displayed were only in black and white text.
* REVIEW OF RELATED LITERATURE

American Standard Code for Information Interchange (hereafter referred
to as ASCII) is popularly used as a text file format in which 128
alphabetic, numeric, or special character is represented by 7-bit
binary numbers. Its prominent utilization is found in many operating
systems such as those that are UNIX or DOS(Disk Operating System)-based
citep:rouse2005ascii.

ASCII art employs the ASCII character set in creating images or
diagrams, ranging from simple representations of faces
(e.g. emoticons) to more complex renditions. This is used due to its
universality as a computer art form, meaning every computer system
capable of multi-line text display is able to display the art without
particular graphic file formats. Its file size is also significantly
smaller than any graphic file format citep:cjrandall2004faq.

cite:xu2010structure shows a new algorithm separate from SSIM in order to produce ASCII art.
The algorithm they produced mimics ``deformation,'' an ASCII artist technique that professional ASCII artists use;
it deforms the image and sacrifices visual accuracy in order to
make it clearer as the ASCII art ``pixels'' are inherently more limited than actual pixels.

Although it has advantages over the usage of actual images, the
generation of structure-based ASCII art may be challenging as the
reproduction and translation from image to text could distort the
resulting rendition. A factor that could affect this may be excessive
amounts of texture in the base images. This obstacle may be resolved
through separating the weak structure within the natural photos from
the original crowded texture, resulting in more distinguishable
results citep:xu2017ascii.

cite:ogrady2008automatic aims for a bitmap approach --
it produces ASCII art that is concerned about the shape of filled objects
rather than the outline of the objects.
ASCII art renders like this tend to be more appropriate for backgrounds,
where contrast is less important and visual clarity is sacrificed for a more scenic artwork.

cite:miyake2011interactive points out that different pictures have require different treatment and thus
created an interactive system to allow users to
choose the most appropriate rendering method for the given image.

cite:singh2015research states that C language were utilized among the many programming languages available for the development of this project.
It is a structured and methodical language used both for operating systems (OS) and applications
with a wide following in the academic community.
It is one of the most important basic courses of study in science and engineering college.

C was developed at Bell Laboratories in 1972 by American computer scientist Dennis Ritchie.
Its features were derived from an earlier language called ``B,'' a derivative of Basic Combined Programming Language(BCPL) and
was originally invented for implementing UNIX operating system.
To this day, it is best known for its reliability, portability, flexibility, interactivity, modularity, efficiency, and effectiveness citep:singh2015research.

In cite:cprogramming, it is made known that the C language is a statically typed imperative language.
It features much of basic and derived data types, structures and unions, operators, flow controls, and more.
It is closely linked to the computer's hardware, thus changing its performance based on whether the system is in 32-bit or 64-bit,
which may result in different data type representation.

For many decades, C has been used as a base language for many video games, with or without graphics.
An ideal and completely functional game is a perfect combination of actions-reactions or event-responses the responses are based on the most-recently occurred event.
C's basic methodical and systematic nature therefore makes it efficient for this logic development citep:jacob2013.

Visual Novels are a medium using the narrative fashion of Literature,
however in a digital format that could technically considered a video game.
They have a tendency to put more emphasis on the plot and on characterization,
in preference to on action scenes, like interactive fiction and more so than Adventure Games.
Visual Novels are successfully seen as a virtual evolution of Choose Your Own Adventure books,
with music, pictures, and occasionally even voice acting or movies.
However, unlike most Choose Your Own Adventure books,
they normally branch off into distinct storylines early on,
and may have plenty more choice points (since they're virtual and consequently do not suffer from physical barriers.)
Puzzle, quests and escape games are often embedded within the plot to be able to strengthen the story-line(s) citep:visualnovel.

cite:crimmins2016 states that visual novels aren't a static object.
They've changed a lot since their inception,
so limiting them to just one definition risks overlooking important historical developments.
In fact, when we examine visual novel history in greater detail,
we see the genre operating on at least two distinct definitions.
Where earlier visual novels told their stories primarily through manga-like composition,
the modern visual novel (where character portraits tell the story through theatrical presentation) was a later development.
Each type had their own unique origins, and each had a significant impact on how visual novels conveyed narrative.

cite:cavallaro2010anime states that the visual novel typically articulates its narrative
by means of extensive text conversations complemented by lovingly depicted generic backgrounds and dialogue boxes
with characters sprites determining the speaker superimposed upon them.

cite:nagle2001 games can be a very effective way to develop
metastrategies. It means trying out a lot of strategies and seeing if
they work, allocating resources and role-playing. Perhaps the very act
of role-playing in a game context helps a player to adopt multiple
viewpoints.

cite:evans2008 Video games provide a diverse set of experiences and
related activities and are part of the lives of almost all teens in
America. To date, most video game research has focused on how games
impact academic and social outcomes.

* METHODOLOGY

** Programming
The following documents the theorems that increase the performance of the code
, the algorithms that were used
, and the actual code.
#+LATEX: \newcommand\R{\mathbb{R}}
#+LATEX: \newcommand\eR{\overline{\R}}
\newtheorem{theorem}{Theorem}
#+NAME: theorem:summation
#+BEGIN_theorem
Given a 0-indexed list where the length was a multiple of a, the summation formula
\begin{align*}
\sum\limits_{i = 0}^{n - 1} x_{i}
\end{align*}
is equivalent to
\begin{align*}
\sum\limits_{i' = 0\mathstrut}^{a} \sum\limits_{i = 0\mathstrut}^{\frac{n}{a}} x_{ai + i'}
\end{align*}
#+END_theorem

#+NAME:theorem:sortedlist
#+BEGIN_theorem
Given an element, \(a \in \R\),
one can once again define a function \(f_a : \R \to \eR\), that maps \(b \mapsto d(b,a)\).
Now, given points \(x, y \in \R\), if \(f_a x < f_a y\) then x was the optimal element.

#+END_theorem
*** Luminosity
The luminosity or brightness of the two sprites were compared to one another and
the following metric was used in order to determine which sprite to use.
The definition used for luminosity in this study was the arithmetic mean:
\begin{align}
\frac{1}{n}\sum\limits_{i = 0}^{n - 1} x_{i}
\end{align}
of the pixel values; where
\(x_i\) was the \(i\)th pixel value; and
\(n\) was the number of pixels in the window.
Applying Theorem [[theorem:summation]], with \(a = 8\) for AVX2, we get the following:
\begin{align}
\frac{1}{n} \sum\limits_{i' = 0\mathstrut}^{8} \sum\limits_{i = 0\mathstrut}^{\frac{n}{8}} x_{8i + i'}
\end{align}

# TODO: GCC auto-vectorization
In order to increase the performance,
GNU Compiler Collection(hereinafter referred to as GCC)'s auto-vectorization was used.
This results in the following code
\begin{lstlisting}
for (i = 0;
      i < length(xarray);
      i += 8)
  {
   for (i_ = 0; i_ < length(partialsumx); ++i_)
    {
  	  partialsumx[i_] += xarray[i + i_];
  	  partialsumy[i_] += yarray[i + i_];
    }
  }
  for (int i = 0; i < 3; ++i)
	  {

		  hadd(partialsumx);
		  hadd(partialsumy);
	  }
  for (int i = 0; i < 8; ++i)
	  {
		  partialsumx[i] /= n;
		  partialsumy[i] /= n;
	  }
  mean_x = partialsumx[0];
  mean_y = partialsumy[0];
\end{lstlisting}

A cache was built and stored in an ordered array and
a linear search was then performed and
the most luminous character glyph
less than the luminosity of the region glyph was selected as the most appropriate glyph.

In order to choose the most appropriate glyph,
an extended quasimetric space was defined as follows:
\begin{equation}
{
\setstretch{1.0}
\begin{split}
d : \mathbb{R} \times \mathbb{R} \to [0, \infty]\\
d(x, y) =
\begin{cases}
y - x & x \leq y\\
\infty & y < x
\end{cases}
\end{split}
}
\end{equation}
It can observed that \(x \leq y < z \implies d(x, y) < d(z, y)\)
due to the ordering \(\forall x \in \eR: x \leq \infty\).
Applying theorem [[theorem:sortedlist]], the optimal element can be obtained by checking the elements themselves,
that was given that \(y\), our focal element, if our test element, \(x_i\) was less than \(y\)
while the next element \(x_{i+1}\) was greater than \(y\) then \(x_i\) was the optimal element.
This was visible in the following code:
\begin{lstlisting}
qsort(cache, font_charset->n, sizeof(*cache), cmp_cache);
for (size_t i = 0; i < dest->width; ++i)
	{
		for (size_t j = 0; j < dest->height; ++j)
			{
				size_t k = 0;
				while (k < LENGTH(cache) &&
				       cache[k].value < *index_gray((struct imagebuffer *) dest, i, j))
					{
						++k;
					}
				--k;
				*index_gray((struct imagebuffer *) dest, i, j) = cache[k].character;
			}
	}
\end{lstlisting}
where \lstinline{cmp_cache} was defined as
\begin{lstlisting}
int
cmp_cache(const void *x, const void *y)
{
	return ceil(((const struct cache *) x)->value -
	            ((const struct cache *) y)->value);
}
\end{lstlisting}

*** Structural SIMilarity (SSIM)
The Structural SIMilarity(hereinafter referred to as SSIM) method was used in order to not only gauge the luminosity of the sprites
but also the contrast and structural similarity.
SSIM was not a single metric but rather a combination of 3 metrics --
luminosity, calculated as the arithmetic mean;
contrast, calculated as the population variance; and
structure, calculated as the covariance of the 2 sprites.

The formula for luminosity had already been presented;
both contrast and structure relies on the covariance algorithm.
The moment was calculated using the formula:
\begin{equation}
C = \sum\limits_{i=1}^n (x_i - \overline{x})(y_i - \overline{y})
\end{equation}
where \(\overline{x}_n\) and \(\overline{y}_n\) were the means as calculated in the previous section,
and the covariance being calculated as
\begin{equation}
\sigma_{XY} = \text{Cov}(X,Y) = \frac{C_n}{n}
\end{equation}
and the variance being calculated as
\begin{equation}
\sigma_X^2 =\text{Var}(X) = \text{Cov}(X,X)
\end{equation}
Once again, to exploit GCC's auto-vectorization, we apply Theorem [[theorem:summation]],
with \(n=8\) as AVX operates on 8 \lstinline{float}s resulting in the following definition:
\begin{equation}
C = \sum\limits_{i' = 0\mathstrut}^{8} \sum\limits_{i = 0\mathstrut}^{\frac{n}{8}} (x_{8i + i'} - \overline {y})(y_{8i + i'} - \overline {y})
\end{equation}
And the equivalent code was:
\begin{lstlisting}
for (i = 0;
     i < length(xarray);
     i += 8)
 {
  for (i_ = 0; i_ < length(partialsumx); ++i_)
	  {
		  float xdiff = xarray[i + i_] - partialsumx[i_];
		  float ydiff = yarray[i + i_] - partialsumy[i_];

		  partialsumvarx   [i_] += xdiff*xdiff;
		  partialsumvary   [i_] += ydiff*ydiff;
		  partialsumcovarxy[i_] += xdiff*ydiff;
	  }
 }
for (int i = 0; i < 8; ++i)
 {
  var_x    += partialsumvarx   [i];
  var_y    += partialsumvary   [i];
  covar_xy += partialsumcovarxy[i];
 }
// Account for 0-padding
var_x    += pad*mean_x*mean_x;
var_y    += pad*mean_y*mean_y;
covar_xy += pad*mean_x*mean_y;
\end{lstlisting}

Finally, the luminosity, contrast and structure were calculated using
\begin{align}
\begin{split}
l(x,y)&=\frac{2\mu_x\mu_y + c_1}{\mu^2_x + \mu^2_y + c_1}\\
c(x,y)&=\frac{2\sigma_x\sigma_y + c_2}{\sigma^2_x + \sigma^2_y + c_2}\\
s(x,y)&=\frac{2\sigma_{xy} + c_3}{\sigma_x \sigma_y + c_3}
\end{split}
\end{align}
where
\(c_1 = (k_1L)^2\),
\(c_2 = (k_2L)^2\),
\(c_3 = \frac{c_2}{2}\), and
\(L = 2^n - 1\) where \(n\) refers to the number of bits per pixel.

The SSIM formula was defined by the luminosity, contrast and structure.
\begin{equation}
\text{SSIM}(x,y) = \left[ l(x,y)^\alpha \cdot c(x,y)^\beta \cdot s(x,y)^\gamma \right]
\end{equation}
where the weights were typically \(\alpha = \beta = \gamma = 1\).

** Testing
Portable Network Graphics(hereinafter referred to as PNG, or png) images were taken from cite:fei2007learning
and the ASCII art was renderer was run in batch mode, a mode that performs the rendering operation to multiple files in order to assess the robustness of the program.
Technically, this did not prove that the program was correct but this proves that there is a high probability that it was either correct or incorrect.
As natural images are often encoded as Joint Photographic Experts Group(JPEG) files,
we used ImageMagick's \texttt{convert} in conjunction with GNU \texttt{parallel} by cite:Tange2011a.

After that, the following bash script was ran in order to check if the program works for all files used by cite:Tange2011a:
\begin{lstlisting}[language=bash]
errors=0; count=0;
for i in ../images/101_ObjectCategories/*; do
  for j in $i/*.png; do
    count=$((count + 1));
    ./asciivn --benchmark --file $j || errors=$((errors + 1));
    echo "COUNT: "$count;
  done;
done;
echo "ERRORS:" $errors
\end{lstlisting}

** Survey
Following the works of cite:xu2010structure,
participants were asked to rate on a 1-6 scale on the accuracy and clarity of the generated ASCII art, a pre-rendered versions of other ASCII arts.
Once the data was collected, the data was treated in two ways in order to objectively measure on how well it compares to the source image
and how well it compares to other rendering methods.
*** Sampling Method
Quota sampling was chosen for selecting the participants of our survey.
This was employed to ensure that people with our desired characteristics were able to participate in our survey and give their opinion as to whether our research product was successful in reproducing an image in the ASCII format.
Our target population were the entire school population and were divided into two categories, the first being those who were knowledgeable and well-versed in ASCII art and those who don’t know or were indifferent about ASCII art in general.
As for the location of our surveys, it took place at high-density population areas inside the University of San Carlos both in the North Campus and the Talamban Campus.

For the sample size, we have determined that at most, we require 60 people participate in our survey, with 30 people in each of our strata.
This was because, for the sake of cost-efficiency, we were following the central limits theorem,
which states that a large sample size was approximately normally distributed regardless of the distribution of population one samples from.
*** Survey form
The survey form consists of the source dog image and the rendered image.
The survey questions consist of a 1-6 scale measuring the
perceived clarity of the generated ASCII art
and its accuracy to the source image.
# *** Efficiency
# The efficiency was calculated using the following formula:
#
# #+NAME:equation:efficiency
# \begin{equation}
# \textrm{Efficiency} = \frac{\textrm{Acc}*\textrm{Clarity}}{t*\textrm{Rows}*\textrm{Cols}}
# \end{equation}
# where \(t\) refers to the time to render the image.

# *** Comparison to other rendering methods
# To compare it with other rendering methods,
# the mean and the standard deviation were calculated, and
# we performed the difference of two means test.

* RESULTS AND DISCUSSION
The output of the \texttt{bash} command gave us a count of 9144 with 0 errors,
which means that there were no errors in the dataset of cite:fei2007learning;
this is tabulated in Table [[table:robustness]]
This shows that given a well-formed PNG file,
the program was sure to terminate without any errors.

#+CAPTION: Robustness test results
#+NAME: table:robustness
#+ATTR_LATEX: :options [h]
|---------+--------+--------+---------------|
|---------+--------+--------+---------------|
| Batch # | Images | Errors | Error Percent |
|---------+--------+--------+---------------|
|       0 |   1000 |      0 |            0% |
|       1 |   1000 |      0 |            0% |
|       2 |   1000 |      0 |            0% |
|       3 |   1000 |      0 |            0% |
|       4 |   1000 |      0 |            0% |
|       5 |   1000 |      0 |            0% |
|       6 |   1000 |      0 |            0% |
|       7 |   1000 |      0 |            0% |
|       8 |   1000 |      0 |            0% |
|       9 |    144 |      0 |            0% |
|---------+--------+--------+---------------|
|   Total |   9144 |      0 |            0% |
|---------+--------+--------+---------------|
|---------+--------+--------+---------------|
The data, found in Table [[table:results]] obtained from the survey suggests that, in general,
majority of the respondents thought that the program was adequate, both
in terms of clarity and accuracy, in fulfilling its purpose. This
means that the program was able to successfully replicate an image in
ASCII that can be easily recognized and identified by the majority of
the respondents. However, in terms of clarity there was a slight
decrease of the people who thought highly of the replicated image in
ASCII art compared to its accuracy. This may be due to the fact that
the generated ASCII art contained spurious lines due to interference
from neighboring points. Furthermore, only a single sample was shown
out of the sets of images that were actually generated.

Although, a lot of participants were able to recognize the
similarities between the two objects, namely the original picture and
the ASCII-generated picture, they were still not satisfied with the
program's capabilities to generate clear a ASCII-art image. To combat
this, a feature was added to the program, so that the user
can adjust the resolution of the generated ASCII-art and adjust the
font size so that it can fit more lines of text into the ASCII-image,
meaning more detailed and higher resolution ASCII-generated images.

#+CAPTION: Survey results
#+NAME: table:results
#+ATTR_LATEX: :options [h]
|----------+-----+--------+------|
|----------+-----+--------+------|
|          | Low | Medium | High |
|----------+-----+--------+------|
| Clarity  |   9 |     33 |   18 |
| Accuracy |   3 |     25 |   32 |
|----------+-----+--------+------|
|----------+-----+--------+------|
More images can be found in Appendix B.

# we were able to get running speeds of \SI{0.15}{\second}.
# Using [[equation:efficiency]], we get
# \[
# \textrm{Efficiency} = \frac{3.8*4.6}{0.15*82*272} = 0.00522
# \]

* SUMMARY, CONCLUSION AND RECOMMENDATIONS
** Summary
In the study, an ASCII art rendering program was developing using
SSIM or structural, and tone-based methods.
A survey was conducted and results have shown that most people found it
accurate and clear.
A robustness test was also done by feeding the program 9144 images,
all of which passed.
We expect that this program will be able to accept any images that it was given.

** Conclusion
The ASCII art generated was generally accurate and clear enough for the respondents.
Furthermore, the program was very robust -- even when given 9144 images,
none crashed the program nor failed to render.

** Recommendation
We acknowledge that the research can be improved in the following aspects:
first, color output should be explored in succeeding researches;
second, the program should work with JPEG,
and third, the program should explore other rendering methods such as cite:xu2010structure.
On the paper itself, we recommend derivative researches to compare the output to existing rendering methods.
In terms of performance,
BLAS/LAPACK citep:Anderson:1990:LPL:110382.110385, and
OpenCL citep:opencl can be used.


#+LATEX: \clearpage
#+LATEX: \addcontentsline{toc}{section}{REFERENCES}
#+LATEX: \renewcommand{\refname}{REFERENCES}
#+LATEX: \ifexport \setstretch{1} \fi
#+LATEX: \ifexport \setlength{\bibitemsep}{12pt} \fi

* REFERENCES
  :PROPERTIES:
  :UNNUMBERED: t
  :END:
#+LATEX: \defbibheading{subsecbib}[\bibname]{%
#+LATEX:   \subsection*{#1}%
#+LATEX:   \markboth{#1}{#1}}
#+LATEX: \printbibliography[heading=subsecbib, check=article, title={Article}]
#+LATEX: \printbibliography[heading=subsecbib, check=journal, title={Journal}]
#+LATEX: \printbibliography[heading=subsecbib, check=website, title={Website}]
# #+LATEX: \printbibliography

#+LATEX: \clearpage
* APPENDICES
  :PROPERTIES:
  :UNNUMBERED: t
  :END:
#+LATEX: \newappendix{Appendix A: Survey Questionnaires}
#+LATEX: \begin{center}
#+LATEX: \includegraphics[width=\linewidth]{Survey}
#+LATEX: \end{center}

#+LATEX: \clearpage
#+LATEX: \newappendix{Appendix B: Rendered Images}
#+LATEX: \begin{center}
#+LATEX: \includegraphics[width=\linewidth]{Bird}
#+LATEX: \includegraphics[width=\linewidth]{Ene}
#+LATEX: \includegraphics[width=\linewidth]{Girl}
#+LATEX: \includegraphics[width=\linewidth]{Madness}
#+LATEX: \includegraphics[width=\linewidth]{Neko}
#+LATEX: \end{center}

# Local Variables:
# mode: org
# org-latex-pdf-process: ("lualatex -interaction nonstopmode -output-directory %o %f" "biber %b"  "makeglossaries %b" "lualatex -interaction nonstopmode -output-directory %o %f" "lualatex -interaction nonstopmode -output-directory %o %f")
# org-latex-caption-above: t
# End:
